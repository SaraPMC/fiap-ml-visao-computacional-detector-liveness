{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05w1A84om8LV"
      },
      "source": [
        "# MBA FIAP Inteligência Artificial & Machine Learning\n",
        "\n",
        "## Visão Computacional: Análise de Imagens Médicas\n",
        "\n",
        "> Atenção: este notebook foi desenhado para funcionar no **Google Collab**.\n",
        "\n",
        "\n",
        "## 1. Introdução\n",
        "\n",
        "Uma determinada fintech focada em consumidores finais pessoa física constataou um grande número de fraudes em transações bancárias.\n",
        "\n",
        "O setor de fraudes apontou que existem clientes que se queixaram de não contratar serviços específicos, como o crédito pessoal, e após isso transferir para outras contas desconhecidas. \n",
        "\n",
        "Após análises pelas equipes de segurança, os protocolos de utilização da senha foram realizados em conformidade, ou seja, cada cliente autenticou com sua própria senha de maneira regular.\n",
        "\n",
        "Em função disso, o banco precisa arcar com reembolsos e medidas de contenção para evitar processos judiciais, pois os clientes alegam terem sido invadidos por hackers ou algo parecido.\n",
        "\n",
        "Uma das formas de solucionar ou minimizar este problema é com a utilização de outras formas de autenticação, sobretudo em operações críticas, como a obtenção de crédito pessoal.\n",
        "\n",
        "Desta forma podemos implementar uma verificação de identidade com prova de vida (liveness), que utilize uma verificação e identificação facial. \n",
        "\n",
        "Caso o cliente não seja autenticado, ele será atendido por uma esteira dedicada e as evidências da não identificação serão encaminhadas para a área de IA para validação dos parâmetros e limiares para aperfeiçoamento do modelo.\n",
        "\n",
        "Será necessário construir:\n",
        "\n",
        "* Detector de faces\n",
        "* Identificação de faces (podendo ser um comparador entre um rosto de documento e outra da prova de vida)\n",
        "* Detecção de vivacidade (liveness) para evitar que um fraudador utilize uma foto estática.\n",
        "\n",
        "\n",
        ">Formas alternativas de prover a identificação e prova de vivacidade, além destas que foram solicitadas poderão ser submetidas.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/michelpf/fiap-ml-visao-computacional-detector-liveness/blob/master/notebook/imagens/liveness.jpg?raw=1\">\n",
        "</p>\n",
        "\n",
        "Imagem retirada do [Grunge](https://www.grunge.com/192826/company-testing-robocop-facial-recognition-software-with-us-police/).\n",
        "\n",
        "## 2. Instruções\n",
        "\n",
        "Este projeto final tem como objetivo explorar os conhecimentos adquiridos nas aulas práticas.\n",
        "\n",
        "Iremos constuir uma forma de validar se uma determinada imagem foi ou não adulterada e se trata de uma produção fraudade.\n",
        "\n",
        "Existem diversas formas de validar a vivacidade, e neste sentido conto com a criatividade de vocês dado que já dominam encontrar uma face numa imagem, aplicar marcos faciais e até mesmo construir uma rede neural convulacional.\n",
        "\n",
        "A abordagem mais simples é pela construção de uma rede neural com imagens de fotos de rostos de outras fotos e fotos de rostos sem modificações. Tal classificador deverá classificar se dada imagem possui vivacidade ou não com uma pontuação de probabilidade.\n",
        "\n",
        "Referências que abordam o tema para servir de inspiração:\n",
        "\n",
        "1. [PyImageSearch](https://pyimagesearch.com/2019/03/11/liveness-detection-with-opencv/), Liveness detection with OpenCV;\n",
        "2. [Kickertech](https://kickertech.com/face-liveness-detection-via-opencv-and-tensorflow/), Liveness detection via OpenCV and Tensorflow.\n",
        "3. [Towards Data Science](https://towardsdatascience.com/real-time-face-liveness-detection-with-python-keras-and-opencv-c35dc70dafd3?gi=24f8e1b740f9), Real-time face liveness detection with Python, Keras and OpenCV.\n",
        "\n",
        "Este projeto poderá ser feita por grupos de até 4 pessoas.\n",
        "Caso este projeto seja substitutivo, deverá ser realizado por apenas uma pessoa.\n",
        "\n",
        "| Nome dos Integrantes     | RM            | Turma |\n",
        "| :----------------------- | :------------- | :-----: |\n",
        "| Integrante 1             | RM 12345      | XIA |\n",
        "| Integrante 2             | RM 12345      | XIA |\n",
        "| Integrante 3             | RM 12345      | XIA |\n",
        "| Integrante 4             | RM 12345      | XIA |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IDENTIFICAÇÃO DE FACES\n",
        "#DETECÇÃO DE FACES\n",
        "2.5"
      ],
      "metadata": {
        "id": "23gKZYI_qSm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.spatial import distance as dist"
      ],
      "metadata": {
        "id": "mTJLoo3-qZJM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem = cv2.imread(\"imagens/px-woman-smilings.jpg\")\n",
        "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "EU3CcwYdzRdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(imagem)"
      ],
      "metadata": {
        "id": "5dmIjZXkzVQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_dlib_68_path = \"classificadores/shape_predictor_68_face_landmarks.dat\"\n",
        "classificador_dlib = dlib.shape_predictor(classificador_dlib_68_path)\n",
        "detector_face = dlib.get_frontal_face_detector()"
      ],
      "metadata": {
        "id": "BttJi1tRqZP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anotar_rosto(imagem):\n",
        "    retangulos = detector_face(imagem, 1)\n",
        "    \n",
        "    if len(retangulos) == 0:\n",
        "        return None\n",
        "    \n",
        "    for k, d in enumerate(retangulos):\n",
        "        print(\"Identificado rosto \" + str(k))\n",
        "        cv2.rectangle(imagem, (d.left(), d.top()), (d.right(), d.bottom()), (255, 255, 0), 2)\n",
        "    \n",
        "    return imagem"
      ],
      "metadata": {
        "id": "Oh_uQl3Jwa7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_anotada = imagem.copy()\n",
        "imagem_anotada = anotar_rosto(imagem_anotada)"
      ],
      "metadata": {
        "id": "_2L-VMF6zfrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(imagem_anotada)"
      ],
      "metadata": {
        "id": "HoaTEpDSzfwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pontos_marcos_faciais(imagem):\n",
        "    retangulos = detector_face(imagem, 1)\n",
        "    \n",
        "    if len(retangulos) == 0:\n",
        "        return None\n",
        "    \n",
        "    marcos = []\n",
        "    \n",
        "    for ret in retangulos:\n",
        "        marcos.append(np.matrix([[p.x, p.y] for p in classificador_dlib(imagem,ret).parts()]))\n",
        "    \n",
        "    return marcos"
      ],
      "metadata": {
        "id": "Qg90uxl9zf1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marcos_faciais = pontos_marcos_faciais(imagem)"
      ],
      "metadata": {
        "id": "DIJBM1k1wbAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anotar_marcos_faciais(imagem, marcos):\n",
        "    \n",
        "    for marco in marcos:\n",
        "        for idx, ponto in enumerate(marco):\n",
        "            centro = (ponto[0,0], ponto[0,1])\n",
        "            cv2.circle(imagem, centro, 3, (255,255,0), -1)\n",
        "            cv2.putText(imagem, str(idx), centro, cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
        "                       (255,255,255), 2)\n",
        "    \n",
        "    return imagem"
      ],
      "metadata": {
        "id": "Zpr5FpNmwbFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_anotada = imagem.copy()\n",
        "imagem_anotada = anotar_marcos_faciais(imagem_anotada, marcos_faciais)"
      ],
      "metadata": {
        "id": "gqYkw6rPzsIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(imagem_anotada)"
      ],
      "metadata": {
        "id": "QUeZaKTIzt9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ma4gHldAqZWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozNhLc9zm8Ld"
      },
      "source": [
        "## 3. Abordagem e organização da solução do problema (2 pontos)\n",
        "\n",
        "Como o grupo pretende deteccar a prova de vivacidade de uma determinada imagem? Quais os passos e os building blocks deste processo?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "O primeiro passo é identificar através de uma câmera todos ou alguns desses pontos em comum, como os dois olhos e a distância entre eles,\n",
        "o nariz e seu comprimento, a boca, as bochechas e o queixo, limitando assim o formato da face e o espaço ocupado por ela.\n"
      ],
      "metadata": {
        "id": "vlLfdD_EoAdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC8mqDCFm8Lf"
      },
      "source": [
        "**Resposta**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts4FpT20m8Lg"
      },
      "source": [
        "## 4 Desenvolvimento da solução (5,5 pontos)\n",
        "\n",
        "Detalhe o passo-a-passo do algoritmo de deteção de vivacidade.\n",
        "Se optar pela construção e treinamento de um modelo de redes neurais convulucionais, apresente a arquitetura, prepare os dados de treinamento, realize o treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNGpZT17m8Lh"
      },
      "source": [
        "### 4.1 Organização de dados para treinamento de modelo de liveness (2 pontos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDtJfN4nm8Lh"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTAR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4LsC3aLm8Li"
      },
      "source": [
        "### 4.2 Treinamento de modelo de liveness (1,5 pontos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0R8RHbnm8Lj"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OTTxy6Nm8Lk"
      },
      "source": [
        "### 4.3 Métricas de desempenho do modelo (2 pontos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzQESA_1m8Lk"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3127Azm8Ll"
      },
      "source": [
        "## 5 Teste Fim-a-Fim\n",
        "\n",
        "Simule a operação fim-a-fim, com uma imagem de entrada forjada (foto de foto de um rosto) e outra com uma imagem de rosto, exibindo o resultado da classificação e a pontuação de cada classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwTv4rwRm8Ll"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNRtg_Tbm8Lm"
      },
      "source": [
        ">Com a implementação da solução na forma de uma aplicação do [Streamlit](https://www.streamlit.io/) (veja a pata streamlit-app e use o template) vale 1 ponto adicional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn3dchhgm8Lm"
      },
      "source": [
        "**Pergunta**: Se utilizou o Streamlit, compartilhe a URL do aplicativo publicado:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyNS8qkFm8Lm"
      },
      "source": [
        "**Resposta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVI7OC48m8Ln"
      },
      "source": [
        "## 6 Conclusões (2,5 pontos)\n",
        "\n",
        "**Pergunta**: Dado todo o estudo e pesquisa, quais foram as conclusões sobre a solução, o que funcionou, o que não funcionou e quais os detalhes que observariam numa nova versão e melhorias do processo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ih9vTbXm8Ln"
      },
      "source": [
        "**Resposta**:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "733a071da2455ea0e8bdf5409a7097e630ac701195faf55c6e985d77ee3ec176"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}